{"cells":[{"metadata":{"_cell_guid":"3126e70f-cab2-2a30-615a-4ca30b77f8ab"},"cell_type":"markdown","source":"# Pima Indians Diabetes Database¶\n\n## Usando Keras para predição de Diabetes\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\npil_im = Image.open('../input/logocanal/LOGO PNG.png')\npil_im","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importando classes","execution_count":null},{"metadata":{"_cell_guid":"86eb84b9-6e10-46cf-5088-598b12e7dd53","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importando arquivos do Keras","execution_count":null},{"metadata":{"_cell_guid":"6ddb1465-2483-ae5e-8e5c-251d19e16c6a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint\n\nseed = 42\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lendo arquivo de Diabetes","execution_count":null},{"metadata":{"_cell_guid":"19633fb6-3f7c-2935-105d-f35b233f9157","trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separando em treino e teste","execution_count":null},{"metadata":{"_cell_guid":"093556e8-a476-800d-ce04-197b6698aa2e","trusted":true},"cell_type":"code","source":"# First - split into Train/Test\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop(['Outcome'],axis=1)\n\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b79bc368-922a-06c2-7321-8f443bbe8bc9","trusted":true},"cell_type":"code","source":"# Ensure that fieldnames aren't included\nX_train = X_train.values\ny_train = y_train.values\nX_test  = X_test.values\ny_test  = y_test.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9ab854a9-4ff8-d20f-b6a3-39e9bb040ca8","trusted":true},"cell_type":"code","source":"NB_EPOCHS = 1000  # num of epochs to test for\nBATCH_SIZE = 16\n\n## Create our model\nmodel = Sequential()\n\n# 1st layer: input_dim=8, 12 nodes, RELU\nmodel.add(Dense(12, input_dim=8, activation='relu'))\n# 2nd layer: 8 nodes, RELU\nmodel.add(Dense(8, activation='relu'))\n# output layer: dim=1, activation sigmoid\nmodel.add(Dense(1, activation='sigmoid' ))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy',   # since we are predicting 0/1\n             optimizer='adam',\n             metrics=['accuracy'])\n\n# checkpoint: store the best model\nckpt_model = 'pima-weights.best.hdf5'\ncheckpoint = ModelCheckpoint(ckpt_model, \n                            monitor='val_acc',\n                            verbose=1,\n                            save_best_only=True,\n                            mode='max')\ncallbacks_list = [checkpoint]\n\nprint('Starting training...')\n# train the model, store the results for plotting\nhistory = model.fit(X_train,\n                    y_train,\n                    validation_data=(X_test, y_test),\n                    epochs=NB_EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks_list,\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apresentando histórico do Treino","execution_count":null},{"metadata":{"_cell_guid":"817a2560-1d35-9c54-6300-bf97b13b3848","trusted":true},"cell_type":"code","source":"# Model accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b719352d-c431-dc4d-d1ca-1d177bb42951","trusted":true},"cell_type":"code","source":"# Model Losss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"af79c45e-f1b7-7b7f-b7b9-756b2a075224","trusted":true},"cell_type":"code","source":"# print final accuracy\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4ff78452-cdc7-16f5-2dbc-bb7e873dfe43","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}