{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  ** Introduction to Deep Learning with TensorFlow**\nLab Exercises - Week 7\n\n----------"},{"metadata":{},"cell_type":"markdown","source":"## **Notebook Contents:**\n1. What is Deep Learning?\n2. Machine Learning vs Deep Learning.  \n3. Learning in Neural Networks.\n4. Introduction to Convoluted Neural Network (CNN).\n5. Building an image classifier with Tensor Flow."},{"metadata":{},"cell_type":"markdown","source":"### **Python Libraries:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport os\n\n# TensorFlow\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1. What is Deep Learning?**"},{"metadata":{},"cell_type":"markdown","source":"Deep Learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks.\n\n![](https://i.ibb.co/0jbj5dx/Why-Deep-Learning-1024x742.png)\n\n"},{"metadata":{},"cell_type":"markdown","source":"Deep learning is the name we use for “stacked neural networks”; that is, **networks composed of several layers**.\n\nThe layers are made of nodes. A node is just a place where computation happens, loosely patterned on a neuron in the human brain, which fires when it encounters sufficient stimuli.\n\nHere’s a diagram of what **one node** might look like.\n![](https://i.ibb.co/vDCs0Ly/node.png)"},{"metadata":{},"cell_type":"markdown","source":"A node layer is a row of neuron-like switches that turn on or off as the input is fed through the net. \n\nEach layer’s output is simultaneously the subsequent layer’s input, starting from an initial input layer receiving data.\n\nDeep-learning networks are distinguished from the more commonplace single-hidden-layer neural networks by their depth; that is, the number of node layers through which data must pass in a multistep process of pattern recognition.\n\n**More than three layers (including input and output) qualifies as “deep” learning.**\n![](https://i.ibb.co/rd607Kz/neural-net.png)\n"},{"metadata":{},"cell_type":"markdown","source":"### **2. Machine Learning vs Deep Learning**"},{"metadata":{},"cell_type":"markdown","source":"a. Deep learning performs “end-to-end learning” – where a network is given raw data and a task to perform, such as classification, and it learns how to do this automatically.\n\nA machine learning workflow starts with relevant features being manually extracted from images. The features are then used to create a model that categorizes the objects in the image. With a deep learning workflow, relevant features are automatically extracted from images.\n![](https://i.ibb.co/ZVv1H3N/MLDL.png)"},{"metadata":{},"cell_type":"markdown","source":"b. Deep learning networks often continue to improve as the size of your data increases.\n\n**In machine learning, you manually choose features and a classifier to sort images. With deep learning, feature extraction and modeling steps are automatic.**"},{"metadata":{},"cell_type":"markdown","source":"c. Feature hierarchy, it is a hierarchy of increasing complexity and abstraction. It makes deep-learning networks capable of handling very large, high-dimensional data sets with billions of parameters that pass through nonlinear functions.\n![](https://i.ibb.co/kHdjPjJ/feature-hierarchy.png)\n\nDeep learning architectures have been applied to fields including computer vision, speech recognition, natural language processing, audio recognition."},{"metadata":{},"cell_type":"markdown","source":"### **3. Learning in Neural Networks**"},{"metadata":{},"cell_type":"markdown","source":"**Feed-forward ANNs** allow signals to travel one way only: from input to output. There are no feedback (loops); i.e., the output of any layer does not affect that same layer. Feed-forward ANNs tend to be straightforward networks that associate inputs with outputs.\n\n**Recurrent ANNs** can have signals traveling in both directions by introducing loops in the network. Computations derived from earlier input are fed back into the network, which gives them a kind of memory\n![](https://i.ibb.co/b7dnWVx/Feed-forward-and-recurrent-neural-networks.png)"},{"metadata":{},"cell_type":"markdown","source":"### **4. Introduction to Convoluted Neural Network (CNN)**"},{"metadata":{},"cell_type":"markdown","source":"Convolutional neural network (CNN) is a class of deep neural networks, most commonly applied to analyzing visual imagery. \n\nHere's how a image appears to a system:\n![](https://i.ibb.co/n8BnH0b/Corgi3.png)\n\nWorking of a Convoluted Neural Net: \n![](https://i.ibb.co/5Kxnpf9/CNN.jpg)\n\nMax-pooling:\n![](https://i.ibb.co/nL9532t/max-pooling.jpg)"},{"metadata":{},"cell_type":"markdown","source":"### **5. Building an image classifier with TensorFlow**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Loading the Fashion MNIST Dataset\nfashion_mnist = keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://i.ibb.co/bRDDycY/fashion-mnist-sprite.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Data\ntrain_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Class of clothing the image represents\ntrain_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Data Exploration\nprint(\"Dimensions of the training set: \", train_images.shape)\nprint(\"No. of labels in the training set: \",len(train_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Data Exploration\nprint(\"Dimensions of the test set: \", test_images.shape)\nprint(\"No. of labels in the test set: \",len(test_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sample data item\nplt.figure()\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocessing\ntrain_images = train_images / 255.0\n\ntest_images = test_images / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Images from the training set\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Building a model\n\na. **Model Input** - The first layer must specify the shape of the input. This is done using 'input_shape'.<br>\nb. **Model Layers** - <br>\n\n  i) *Layer Types*: There are a large number of core Layer types for standard neural networks.<br>\n     Some common and useful layer types are: <br>\n\n    Dense: Fully connected layer and the most common type of layer used on multi-layer perceptron models.<br>\n    Dropout: Apply dropout to the model, setting a fraction of inputs to zero in an effort to reduce over fitting.<br>\n    Merge: Combine the inputs from multiple models into a single model.<br>\n  \n  ii) *Activation Function*: Specifies the output function from a node. Tensor Flow supports a range of standard neuron activation function, such as: softmax, rectifier, tanh and sigmoid. <br>  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the model\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation=tf.nn.relu),\n    keras.layers.Dense(10, activation=tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  c. **Model Compilation** - This creates the efficient structures used by Tensor Flow in order to efficiently execute your model during training. Compile() function accepts three important attributes: <br>\n  \n  i) *Model Optimizers*: This is how the model is updated based on the data it sees and its loss function. <br>\n  ii) *Model Loss Functions*: This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction. <br>\n  iii) *Model Metrics*: Metrics are evaluated by the model during training."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"d. **Model Training** - The model is trained on NumPy arrays using the fit() function. Training specifies the number of epochs to train on. <br>\n\nEpochs (epochs) is the number of times that the model is exposed to the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_images, train_labels, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"e. **Evaluate accuracy** - Compare how the model performs on the test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"f. **Model Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Prediction\npredictions = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sample Prediction\npredictions[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Manual Validation\nprint(\"Predicted Value:\", np.argmax(predictions[0]))\nprint(\"Actual Value:\", test_labels[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the predicted item:\ndef plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n  \n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction accuracy \ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array[i], true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10), class_names, rotation=45)\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1]) \n  predicted_label = np.argmax(predictions_array)\n \n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions,  test_labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions, test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions, test_labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Resources:**\na. Deshpande, A. (n.d.). A Beginner's Guide To Understanding Convolutional Neural Networks. Retrieved from <br >adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/ <br>\n\nb.(2019, April 03). Introduction to Convolutional Neural Networks (CNN) with TensorFlow. Retrieved from <br >towardsdatascience.com/introduction-to-convolutional-neural-networks-cnn-with-tensorflow-57e2f4837e18 <br>\n\nc. How To Build Multi-Layer Perceptron Neural Network Models with Keras. (2017, December 16). Retrieved from <br> machinelearningmastery.com/build-multi-layer-perceptron-neural-network-models-keras/ <br>\n\nd. Train your first neural network: Basic classification  |  TensorFlow Core  |  TensorFlow. (n.d.). Retrieved from <br> tensorflow.org/tutorials/keras/basic_classification?authuser=1 <br>\n\ne. Keras  |  TensorFlow Core  |  TensorFlow. (n.d.). Retrieved from <br>\ntensorflow.org/guide/keras?authuser=1 <br>"},{"metadata":{},"cell_type":"markdown","source":"\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}