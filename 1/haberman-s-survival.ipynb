{"metadata":{"_change_revision":0,"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","version":"3.6.3"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"_is_fork":false},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{},"cell_type":"markdown","source":"## Machine Learning and Predictions Survival's"},{"metadata":{"_uuid":"9f5867cbbd8e7c60e1dfd7500c629def7d3de61f","_cell_guid":"ed02c0c4-3913-0348-8c14-be9d46045bdf"},"cell_type":"code","execution_count":null,"source":"\n\nimport pandas\nfrom pandas.tools.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import cross_validation\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom matplotlib.ticker import FormatStrFormatter","outputs":[]},{"metadata":{"_uuid":"9c5558ea2ddedd3e2955eae37caab7f5ce5dcd92","_cell_guid":"a421d3af-f21a-feb7-5d49-11cbb7da929b"},"cell_type":"markdown","source":"**2 Loading the data**\n\nRelevant Information: The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n\nAttribute Information:\n   \n   1. Age of patient at time of operation (numerical)\n   \n   2. Patient's year of operation (year - 1900, numerical)\n   \n   3. Number of positive axillary nodes detected (numerical)\n   \n   4. Survival status (class attribute)\n        \n        1 = the patient survived 5 years or longer\n        \n        2 = the patient died within 5 year\n        \n**Data may be found in** http://mlr.cs.umass.edu/ml/machine-learning-databases/haberman/haberman.data"},{"metadata":{"collapsed":true,"_uuid":"62e87c329ecdfbde352a07900f3b4c5923bb0332","_cell_guid":"c756c5f0-41b1-3022-2d7d-0634a47c8422"},"cell_type":"code","execution_count":null,"source":"#1. Age of patient at time of operation (numerical)\n#2. Patient's year of operation (year - 1900, numerical)\n#3. Number of positive axillary nodes detected (numerical)\n#4. Survival status (class attribute)\n         #1 = the patient survived 5 years or longer\n         #2 = the patient died within 5 year\n        \n# Load dataset\nurl = \"../input/haberman.csv\"\nnames = ['Age', 'Year operation', 'Axillary nodes detected', 'Survival status']\ndataset = pandas.read_csv(url, names=names)","outputs":[]},{"metadata":{"_uuid":"8f571f5c813e63e974db9d25fa6dff6acd2d403c","_cell_guid":"7f1abd81-718d-e7f5-ea88-19d97eebf37c"},"cell_type":"markdown","source":"**3 Data preparation**\n\nIn this phase you enhance the quality of the\ndata and prepare it for use in subsequent steps. Data transformation ensures that the data is in a suitable\nformat for use in your models."},{"metadata":{"_uuid":"917b394735264a14032f400fb116957fc3501637","_cell_guid":"7d7a69aa-5111-585c-1137-f59368ab34b2"},"cell_type":"code","execution_count":null,"source":"dataset.head(5)","outputs":[]},{"metadata":{"_uuid":"e168d029f10a5b41545b65558bbad93fa34fde1d","_cell_guid":"a03acfbb-93ed-dba8-3db8-35cfc447d1b0"},"cell_type":"code","execution_count":null,"source":"dataset.describe()","outputs":[]},{"metadata":{"_uuid":"0d15f68980eb65269be7f985af28016c2fa63dc3","_cell_guid":"aeb3463f-8cdb-4b63-b58e-e0026df3f495"},"cell_type":"markdown","source":"**4 Data exploration**\n\nData exploration is concerned with building a deeper understanding of your data.\nYou try to understand how variables interact with each other, the distribution of the\ndata, and whether there are outliers. To achieve this you mainly use descriptive statistics,\nvisual techniques, plots and simple modeling. "},{"metadata":{"_uuid":"8bdbe67300899e0dd8ada0f82442722c9dfab4dd","_cell_guid":"aab3b64a-c4d4-e193-b1b3-2f46a37b04f1"},"cell_type":"code","execution_count":null,"source":"dataset.plot()\nplt.show()","outputs":[]},{"metadata":{"_uuid":"40e49e191dc464ae629c8bbc47d0b8f955bff71c","_cell_guid":"fdfb5682-770d-c5de-0de0-8e65c8325f3f"},"cell_type":"code","execution_count":null,"source":"# histograms\ndataset.hist()\nplt.show()","outputs":[]},{"metadata":{"_uuid":"386c84aae47310ae1c1c348280c99b87a7a713c8","_cell_guid":"bfc1b471-020b-bff2-4eef-b45868e76b46"},"cell_type":"markdown","source":"** 5 Data modeling or model building**\n\nIn this phase you use models, domain knowledge, and insights about the data you\nfound in the previous steps to answer the research question. You select a technique\nfrom the fields of statistics, machine learning, operations research, and so on. Building\na model is an iterative process that involves selecting the variables for the model,\nexecuting the model, and model diagnostics. \n\n**The modeling phase consists of four steps:**\n\nA model consists of constructs of information called features or predictors and a target\nor response variable. Your model’s goal is to predict the target variable, for example,\ntomorrow’s high temperature. The variables that help you do this and are (usually)\nknown to you are the features or predictor variables such as today’s temperature, cloud\nmovements, current wind speed, and so on. The best models are those that accurately\nrepresent reality, preferably while staying concise and interpretable.\n\n**5.1** Training the model\n\n**5.2** Feature engineering and model selection\n\n**5.3** Model validation and selection\n\n**5.4** Applying the trained model to unseen data"},{"metadata":{"_uuid":"b71b6e19a11304a0daf8b00031eb1f2802e4b73c","_cell_guid":"c14b741a-dcc8-49f3-6c5f-f6f6e6c0a76e"},"cell_type":"markdown","source":"**5.1 Training the model**\n\nWith the right predictors in place and a modeling technique in mind, you can progress\nto model training. In this phase you present to your model data from which it\ncan learn."},{"metadata":{"collapsed":true,"_uuid":"617f1385514e5559ddaa3abe12aa01b21be8590a","_cell_guid":"02ae9e29-4ee1-0eaf-3e0b-1891e5c94ee2"},"cell_type":"code","execution_count":null,"source":"#I made an adaptation of this reference online \n#----> http://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n\narray = dataset.values\nX = array[:,:3]\nY = array[:,3]\nvalidation_size = 0.30\nseed = 10\nX_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, \ntest_size=validation_size, random_state=seed)","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a17609788fb4b89555e15cd36209c636e019791a","_cell_guid":"cfe7214d-312b-ea7f-41a3-15af96ec6743"},"cell_type":"code","execution_count":null,"source":"#I made an adaptation of this reference online \n#----> http://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n\n\n# Test options and evaluation metric\nnum_folds = 20\nnum_instances = len(X_train)\nseed = 10\nscoring = 'accuracy'","outputs":[]},{"metadata":{"_uuid":"fef394e47d440639a50a89b6d53f99d78ba0726f","_cell_guid":"dbb591cd-16dd-085d-22f1-4219f41d37f1"},"cell_type":"markdown","source":"**5.2 Model selection**"},{"metadata":{"_uuid":"065f3c045b32b4598b31f6e46f93610c334e4d91","_cell_guid":"18fa3499-a32d-00cf-312d-110971c09147"},"cell_type":"code","execution_count":null,"source":"#I made an adaptation of this reference online \n#----> http://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n\n\n\n# Spot Check Algorithms\nalgorithms = []\nalgorithms.append(('LR', LogisticRegression()))\nalgorithms.append(('LDA', LinearDiscriminantAnalysis()))\nalgorithms.append(('KNN', KNeighborsClassifier()))\nalgorithms.append(('CART', DecisionTreeClassifier()))\nalgorithms.append(('NB', GaussianNB()))\nalgorithms.append(('SVM', SVC()))\nalgorithms.append(('NN', MLPClassifier()))\nalgorithms.append(('RFC', RandomForestClassifier()))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, algorithm in algorithms:\n    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n    cv_results = cross_validation.cross_val_score(algorithm, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","outputs":[]},{"metadata":{"_uuid":"0c404d04eaaaddb5f2493591effe11868efd42ed","_cell_guid":"98a9963b-ad38-f2c5-c4c9-0067fdc662e9"},"cell_type":"markdown","source":"**5.3 Model validation**\n\nData science has many modeling techniques, and the question is which one is the\nright one to use. A good model has two properties: it has good predictive power and it\ngeneralizes well to data it hasn’t seen. "},{"metadata":{"_uuid":"172b5d05f3de90dbc11d5a7e1e114d5da02b5dce","_cell_guid":"d10fdb5f-d7ee-6e02-1e13-2bd768e09097"},"cell_type":"code","execution_count":null,"source":"# Make predictions on validation dataset\nknn =  GaussianNB()\nknn.fit(X_train, Y_train)\npredictions = knn.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","outputs":[]},{"metadata":{"_uuid":"8c11b45bf0922d0f6fbf57964850320bf521ab63","_cell_guid":"c586391a-75f2-adfc-0066-59a202b2fba3"},"cell_type":"markdown","source":"**5.4 Applying the trained model to unseen data**\n\nFirst, you prepare a data set that has features\nexactly as defined by your model. This boils down to repeating the data preparation\nyou did in step one of the modeling process but for a new data set. Then you apply the\nmodel on this new data set, and this results in a prediction. \n\n\n**Here I've created a dataframe with random attribute values to use as input to the model.**"},{"metadata":{"_uuid":"5c9fb76114c3a9e8c8985b3e5680feb0215c473e","_cell_guid":"23536c15-6200-b199-e648-9d1ed8e4b747"},"cell_type":"code","execution_count":null,"source":"df_data = {'Age': [30,34, 35,38,40,50,43,45,34,34,46,50,45,38,42],\n           'Year os operations': [65,64,63,64,66,64,64,64,63,63,64,67,64,65,67],\n           'axillary nodes detected': [4,10,15,8,40,25,23,40,3,40,3,1,4,2,4]}\ndf = pandas.DataFrame(df_data)\nprint(df)","outputs":[]},{"metadata":{"_uuid":"42aaeba002f7c81e72ff3a25f670bf75251c71b9","_cell_guid":"39e2c11c-512a-31af-167c-0f112122a703"},"cell_type":"code","execution_count":null,"source":"df.plot()\nplt.show()","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a7135310c5790f42616b902dca3c91003fb674d4","_cell_guid":"7e821064-5c64-8590-a3e5-f648828b8910"},"cell_type":"code","execution_count":null,"source":"prediction = knn.predict(df)","outputs":[]},{"metadata":{"_uuid":"3ce8fe8489fae9ea1778244ae0588171cacefcb9","_cell_guid":"30b535ce-0823-5357-37ac-58c69f262fbe"},"cell_type":"code","execution_count":null,"source":"print(\"Prediction of data survival status: {}\".format(prediction))","outputs":[]},{"metadata":{"_uuid":"ea5a575c7f9ce4aaf10d5fed60b09b046d39fa1b","_cell_guid":"b0a9bc6b-4245-d46f-80ab-78308167c019"},"cell_type":"markdown","source":"** Variable Output (Status survival)**"},{"metadata":{"_uuid":"6cf50615bd26a899a56afef790b9edcd25bede5b","_cell_guid":"a549641b-3478-0f87-4fda-8465725361a5"},"cell_type":"code","execution_count":null,"source":"plt.plot(prediction)\nplt.ylabel('Status survival')\nplt.xlabel('index = number of Occurrences')\nplt.show()\n\n","outputs":[]},{"metadata":{"_uuid":"34dbc8f1375eaaad29e9c89bb80270d8472d85bd","_cell_guid":"ca3603a5-47be-673f-0ea7-d448cc1954a1"},"cell_type":"markdown","source":"**Conclusion**\n\nThe machine learning algorithm predicts the status of survival with an index of 75% with input attributes: age, year of operation and number of axillary nodes. Remembering that 1 = the patient survived 5 years or longer and\n2 = the patient died within 5 year."},{"metadata":{"_uuid":"7568cf4b9e17edce5ebd5340de13ec0948bb980c","_cell_guid":"4ff3c974-f6de-0f0c-a894-99b0b1e2dfeb"},"cell_type":"markdown","source":"**Thanks!**"}]}