{"cells":[{"metadata":{},"cell_type":"markdown","source":"# $\\text{Introduction}$\n\n![](https://storage.googleapis.com/kaggle-datasets-images/34436/46048/ef20fcd937e23fe3062cd2b7ab48f212/data-original.jpg?t=2018-06-30-08-42-20)\n\nIn the following Kernel we will try and see can we get some reasonable poems using a simple bigram model and word conditional probabilites.\nwe all know that making a bombastic nlp model on such a small dataset will give us poems that resemble Poes poems and stories. The question I will investigate in this Kernel is how good of a Poem can a bigram model with some randomness produce.\n\nThe logic behind the following code will be as follows:\n1. Create a bigram model of all Poem / Story text's \n2. Create helper functions to extract the probability and decide on the next word using the following probability:\n\nLet $w1$ be the current word we will find all the bigrams that start with $w1$ and calculate $P(w2 | w1 )$ $=>$ $count(w1w2) / count(w1)$ \n\nWe will fill a list with 5 words with the highest probabilities and use another variable $'alpha'$ to decide which word should we take.\nWe will choose a random number from a normal distribution and if this number is larger than $alpha$ we will randomly select a word from the less probable words meaning words 1-4 (without the most probable word at index 0 ).\nelse we will return the most probable word at index 0.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom wordcloud import WordCloud,STOPWORDS\nimport nltk as nlp\nimport string \nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"p_data = pd.read_csv('/kaggle/input/poe-short-stories-corpuscsv/preprocessed_data.csv')\np_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing And Constraction Of Our Text's Language "},{"metadata":{"trusted":true},"cell_type":"code","source":"title_language = []\ntext_language  = []\n\ntitle_bow = {}\ntext_bow = {} \n\nfor index,row in p_data.iterrows():\n    title_language += row['title'].lower().split(' ')\n    text_language += row['text'].lower().split(' ')\n\nfor index,row in p_data.iterrows():\n    title =  row['title'].lower().split(' ')\n    text  = row['text'].lower().split(' ')\n    for te in text:\n        text_bow[te] = text_bow.get(te,0) +1\n    for ti in title:\n        title_bow[ti] = title_bow.get(ti,0) +1\n          \n    \ntitle_language = list(set(title_language))\ntext_language = list(set(text_language))\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_texts = ' '.join(p_data.text.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Helper Functions For N-gram Model Construction And Probability Calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_ngram(n,text):\n    s = text.lower()\n    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n    tokens = s.split(' ')\n    ngrams = zip(*[tokens[i:] for i in range(n)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\nbigram = generate_ngram(2,all_texts)\ndef get_nword_probs(word):\n    contains = [w.split(' ')[1] for w in bigram if w.split(' ')[0] == word and w.split(' ')[1] != '']\n    cont_dic = {}\n    for word in contains:\n        cont_dic[word] = cont_dic.get(word,0)+1\n    occ = len(contains)\n    cont_dic = {word:cont_dic[word]/occ for word in cont_dic.keys()}\n    return cont_dic    \n\ndef get_next_word(cur_word,alpha):\n    prob_dic = get_nword_probs(cur_word)\n    prob_dic_top_5 = sorted(prob_dic, key=prob_dic.get, reverse=True)[:5]\n    if np.random.normal(0,1,1) > alpha and len(prob_dic_top_5)>4:\n        return prob_dic_top_5[int(np.round(np.random.uniform(1,4,1)))]\n    elif len(prob_dic_top_5) == 0:\n        return list(STOPWORDS)[int(np.round(np.random.uniform(0,len(STOPWORDS)-1,1)))]\n    else:\n        return prob_dic_top_5[0]\n\ndef get_random_words(n_words):\n    tsample = p_data.text.sample(int(np.sqrt(n_words)))\n    words = []\n    for i in tsample:\n        words += i.split(' ')\n    choice = np.round(np.random.uniform(0,len(words),n_words))\n    return [words[int(i)] for i in choice]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Poem 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"words = get_random_words(1)\npoem_length = 80\npoem = ''\ncur_word = words[0]\nfor i in range(0,poem_length):\n    poem+= (' '+(get_next_word(cur_word,0.5)))\n    if np.random.normal(0,1,1) >0.8:\n        poem+='\\n'\n    elif np.random.normal(0,1,1) >0.7:\n        poem+=','\n    elif np.random.normal(0,1,1) >0.9:\n        words = get_random_words(5)\n        words = [word for word in words if word not in STOPWORDS]\n        if len(words) == 0:\n            cur_word = get_next_word(cur_word,0.5)\n        else:\n            cur_word = words[0]\n    else:\n        cur_word = get_next_word(cur_word,0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(poem)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Poem 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"words = get_random_words(1)\npoem_length = 80\npoem = ''\ncur_word = words[0]\nfor i in range(0,poem_length):\n    poem+= (' '+(get_next_word(cur_word,0.8)))\n    if np.random.normal(0,1,1) >0.8:\n        poem+='\\n'\n    elif np.random.normal(0,1,1) >0.7:\n        poem+=','\n    elif np.random.normal(0,1,1) >0.9:\n        words = get_random_words(5)\n        words = [word for word in words if word not in STOPWORDS]\n        if len(words) == 0:\n            cur_word = get_next_word(cur_word,0.8)\n        else:\n            cur_word = words[0]\n    else:\n        cur_word = get_next_word(cur_word,0.8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(poem)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Poem 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"words = get_random_words(1)\npoem_length = 120\npoem = ''\ncur_word = words[0]\nfor i in range(0,poem_length):\n    poem+= (' '+(get_next_word(cur_word,0.62)))\n    if np.random.normal(0,1,1) >0.8:\n        poem+='\\n'\n    elif np.random.normal(0,1,1) >0.7:\n        poem+=','\n    elif np.random.normal(0,1,1) >0.9:\n        words = get_random_words(5)\n        words = [word for word in words if word not in STOPWORDS]\n        if len(words) == 0:\n            cur_word = get_next_word(cur_word,0.62)\n        else:\n            cur_word = words[0]\n    else:\n        cur_word = get_next_word(cur_word,0.62)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(poem)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}