{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How to deal with Missing Values in Machine Learning Problems ?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Most of the Machine Learning Problems contains lots of missing values that create a hurdle while training a Machine Learning \nModel. In this notebook you will find some common ways to deal with these missing values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imporing the required Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Train and Test files\n\ntrain=pd.read_csv(r'/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest=pd.read_csv(r'/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ploting the missing values using Heatmap\n\nplt.figure(figsize = (10,6))\nsns.heatmap(train.isnull())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# To find the number of Missing Values in each Columns\n\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its better to drop columns which have more than 50% missing value than filling it. Because it may lead our model in wrong direction and may have huge errors in prediction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping columns which have more than 50% Missing Values\n\ntrain=train.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)  \ntest = test.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating Numerical and Categorical columns\n\ntrain_num_cols = train.select_dtypes(exclude='object').columns\ntrain_cat_cols = train.select_dtypes(include='object').columns\n\n\ntest_num_cols = test.select_dtypes(exclude='object').columns\ntest_cat_cols = test.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_num_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling Missing Values (Numerical Features) using mean of all non null values.\n\nfor i in range(0, len(train_num_cols)):\n    train[train_num_cols[i]] = train[train_num_cols[i]].fillna(train[train_num_cols[i]].mean())\n    \nfor i in range(0, len(test_num_cols)):\n    test[test_num_cols[i]] = test[test_num_cols[i]].fillna(test[test_num_cols[i]].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling Missing Values (Categorical Features) using mode of all non null values.\n\nfor i in range(0, len(train_cat_cols)):\n    train[train_cat_cols[i]] = train[train_cat_cols[i]].fillna(train[train_cat_cols[i]].mode()[0])\n    \nfor i in range(0, len(test_cat_cols)):\n    test[test_cat_cols[i]] = test[test_cat_cols[i]].fillna(test[test_cat_cols[i]].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: To handle missing values of Categorical Features we do not use mean/median because we cannot find mean/median of strings.\n      while any of mean/median/mode can be used for Categorical Feature.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Give it a try**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Upvote if you like this notebook and feel free to ask your doubts in commnet section.\n### Thank You:)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}