{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfrom sklearn.preprocessing import LabelEncoder  ###for encode a categorical values\nfrom sklearn.model_selection import train_test_split  ## for spliting the data\nfrom lightgbm import LGBMRegressor    ## for import our model\nfrom sklearn.preprocessing import LabelEncoder\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's import our data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dataset = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's split our data into X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_dataset.iloc[:,1:-1]\ny = train_dataset.iloc[:,-1] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's check for a NULL values"},{"metadata":{"trusted":true},"cell_type":"code","source":"x.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** There are null values in many column in our X  ** "},{"metadata":{},"cell_type":"markdown","source":"** So we have to find the columns that contain missing values than we will fill with missing values filling techniques **"},{"metadata":{},"cell_type":"markdown","source":"** We have fill numerical columns misssing values with median **\n** We will fill character missing values with most used value count **"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_miss_val = [col for col in train_dataset.columns if train_dataset[col].isnull().any()]\nprint(col_miss_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in col_miss_val:\n    if(x[col].dtype == np.dtype('O')):\n         x[col]=x[col].fillna(x[col].value_counts().index[0])    #replace nan with most frequent\n    else:\n        x[col] = train_dataset[col].fillna(x[col].median()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we have to encode a categorical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"##So first we will find a columns thats contain characters value \nx.select_dtypes(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** So there are many columns that contains character values **"},{"metadata":{"trusted":true},"cell_type":"code","source":"LE = LabelEncoder()\nfor col in x.select_dtypes(include=['object']):\n    x[col] = LE.fit_transform(x[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check the missing values in NULL"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's split the data into Training & testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train , x_test , y_train , y_test = train_test_split(x , y ,test_size = 0.1,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's create our LGBMRegressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lightgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=8,\n                                       learning_rate=0.0385, \n                                       n_estimators=3500,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose= 0,\n                                       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's fit our training data into Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lightgbm.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lightgbm.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Our model created now we have to import test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.isnull().sum()\ntest_dataset = test_dataset.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** There are many missing values in test dataset **"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_col_miss_val = [col for col in test_dataset.columns if test_dataset[col].isnull().any()]\nprint(test_col_miss_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in test_col_miss_val:\n    if(test_dataset[col].dtype == np.dtype('O')):\n        test_dataset[col] = test_dataset[col].fillna(test_dataset[col].value_counts().index[0])    #replace nan with most frequent\n        \n    else:\n        test_dataset[col] = test_dataset[col].fillna(test_dataset[col].median()) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Let's enode a categorical data **"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in test_dataset.select_dtypes(include=['object']):\n    test_dataset[col] = LE.fit_transform(test_dataset[col])   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's predict the test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = lightgbm.predict(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's create a submission.csv of prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'Id': ss.Id,'SalePrice': prediction})\noutput.to_csv('submission.csv', index=False)\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}