{"cells":[{"metadata":{},"cell_type":"markdown","source":"***This Python Notebook detects following languages form a short description of text***\n* **ISO-CODE**     \n* en --> English\t            \n* fr --> French\t            \n* es --> Spanish\t\t             \n* it --> Italian\t             \n* de --> German\t            \n* cz --> Czech\t           \n* sk --> Slovakian\t             "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import load_model\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport keras.optimizers\nfrom ipywidgets import interact_manual\nfrom ipywidgets import widgets\nimport pickle\nimport numpy as np\nimport re","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":18,"outputs":[{"output_type":"stream","text":"['lang_identification_weights.h5', 'input_size.sav', 'standard_scaler.sav']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def define_alphabet():\n    base_en = 'abcdefghijklmnopqrstuvwxyz'\n    special_chars = ' !?¿¡'\n    german = 'äöüß'\n    italian = 'àèéìíòóùú'\n    french = 'àâæçéèêêîïôœùûüÿ'\n    spanish = 'áéíóúüñ'\n    czech = 'áčďéěíjňóřšťúůýž'\n    slovak = 'áäčďdzdžéíĺľňóôŕšťúýž'\n    all_lang_chars = base_en + german +  italian + french + spanish + czech + slovak\n    small_chars = list(set(list(all_lang_chars)))\n    small_chars.sort() \n    big_chars = list(set(list(all_lang_chars.upper())))\n    big_chars.sort()\n    small_chars += special_chars\n    letters_string = ''\n    letters = small_chars + big_chars\n    for letter in letters:\n        letters_string += letter\n    return small_chars,big_chars,letters_string","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sample_text(file_content,start_index,sample_size):\n\n    while not (file_content[start_index].isspace()):\n        start_index += 1\n    while file_content[start_index].isspace():\n        start_index += 1\n    end_index = start_index+sample_size \n    while not (file_content[end_index].isspace()):\n        end_index -= 1\n    return file_content[start_index:end_index]","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_input_row(content,start_index,sample_size, alphabet):\n    sample_text = get_sample_text(content,start_index,sample_size)\n    counted_chars_all = count_chars(sample_text.lower(), alphabet[0])\n    counted_chars_big = count_chars(sample_text, alphabet[1])\n    all_parts = counted_chars_all + counted_chars_big\n    return all_parts","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_xml(text):\n    return re.sub(r'<[^<]+?>', '', text)\n\ndef remove_newlines(text):\n    return text.replace('\\n', ' ') \n    \n\ndef remove_manyspaces(text):\n    return re.sub(r'\\s+', ' ', text)\n\ndef clean_text(text):\n    text = remove_xml(text)\n    text = remove_newlines(text)\n    text = remove_manyspaces(text)\n    return text","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_chars(text, alphabet):\n    alphabet_counts = []\n    for letter in alphabet:\n        count = text.count(letter)\n        alphabet_counts.append(count)\n    return alphabet_counts","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Below Code have following files\n\n**input_size.sav and standard_sacaler are pre-trained pickle files**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the Alphabet\nalphabet = define_alphabet()\nLANGUAGES_DICT = {'en':0,'fr':1,'es':2,'it':3,'de':4,'sk':5,'cs':6}\nLABELS =  list(LANGUAGES_DICT.keys())\n# Length of cleaned text used for training and prediction - 140 chars\nMAX_LEN = 140\n\n# number of language samples per language that we will extract from source files\nNUM_SAMPLES = 250000\n\n\nwith open(\"../input/input_size.sav\", \"rb\") as file_obj:\n    input_size = pickle.load(file_obj)\n\nwith open(\"../input/standard_scaler.sav\", \"rb\") as file_obj:\n    standard_scaler = pickle.load(file_obj)\n    \ndef get_prediction(TEXT):\n    #if len(TEXT) < MAX_LEN:\n    #    print(\"Text has to be at least {} chars long, but it is {}/{}\".format(MAX_LEN, len(TEXT), MAX_LEN))\n    #    return(-1)\n    # Data cleaning\n    cleaned_text = clean_text(TEXT)\n    temp_text=cleaned_text.split(' ')\n    if len(temp_text)<MAX_LEN:\n        count=MAX_LEN-len(temp_text)\n        for i in range(0,count):\n            temp_text.append(\" unk \")\n        cleaned_text=' '.join(temp_text)\n    \n    # Get the MAX_LEN char\n    input_row = get_input_row(cleaned_text, 0, MAX_LEN, alphabet)\n    \n    # Data preprocessing (Standardization)\n    test_array = standard_scaler.transform([input_row])\n    \n    raw_score = model.predict(test_array)\n    pred_idx= np.argmax(raw_score, axis=1)[0]\n    score = raw_score[0][pred_idx]*100\n    \n    # Prediction\n    prediction = LABELS[model.predict_classes(test_array)[0]]\n    print('TEXT:', TEXT, '\\nPREDICTION:', prediction.upper(), '\\nSCORE:', score)\n\n\n\nmodel = Sequential()\n# Note: glorot_uniform is the Xavier uniform initializer.\n\nmodel.add(Dense(500,input_dim=input_size, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(300, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(LANGUAGES_DICT), kernel_initializer=\"glorot_uniform\", activation=\"softmax\"))\nmodel_optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=model_optimizer,\n              metrics=['accuracy'])\n\nmodel.summary()\nmodel.load_weights('../input/lang_identification_weights.h5')\n\n\n","execution_count":24,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 500)               66500     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 300)               150300    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 300)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 100)               30100     \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 7)                 707       \n=================================================================\nTotal params: 247,607\nTrainable params: 247,607\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Lets predict the diffrent lanaguges form sample of text**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(get_prediction(\"This is a sample text in English\"))\nprint(get_prediction(\"Ceci est un exemple de texte en anglais\"))\nprint(get_prediction(\"Dies ist ein Beispieltext in Englisch\"))\n","execution_count":25,"outputs":[{"output_type":"stream","text":"TEXT: This is a sample text in English \nPREDICTION: SK \nSCORE: 43.893611431121826\nNone\nTEXT: Ceci est un exemple de texte en anglais \nPREDICTION: FR \nSCORE: 70.35488486289978\nNone\nTEXT: Dies ist ein Beispieltext in Englisch \nPREDICTION: FR \nSCORE: 42.71645545959473\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}