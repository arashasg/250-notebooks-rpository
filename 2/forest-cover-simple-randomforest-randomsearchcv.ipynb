{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a very basic solution of forestCover problem using RandomForest and followed by hyperparameter tuning  using RandomSerachCV "},{"metadata":{},"cell_type":"markdown","source":"### Fetch Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd \ntrain = pd.read_csv('../input/learn-together/train.csv')\ntest = pd.read_csv('../input/learn-together/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explore data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data set has no missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data set  features ('Wilderness_Area' & 'Soil_Type') are already one hot encoded "},{"metadata":{"trusted":true},"cell_type":"code","source":"#no of unique values in each feature\nfor column in list(train.columns):\n    print (\"{0:25} {1}\".format(column, train[column].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features 'Soil_Type7' and 'Soil_Type15' has only single value hence will be dropped before modeling.\n"},{"metadata":{},"cell_type":"markdown","source":"### Data Modeling"},{"metadata":{},"cell_type":"markdown","source":"#### Train-test split "},{"metadata":{"trusted":true},"cell_type":"code","source":"#  droping not so useful training columns \ndropable_attributes = ['Id','Soil_Type7','Soil_Type15','Cover_Type']\nX = train.drop((dropable_attributes), axis =1)\ny = train['Cover_Type']\n\n# creating test-train set  \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, random_state=42, test_size=.20)\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# define\nrf = RandomForestClassifier()\n# train\nrf.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### cross validation accuracy measure"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracy = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\nacc = accuracy.mean()\nacc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets do hyperparameter tuning using RandomSearchCV"},{"metadata":{},"cell_type":"markdown","source":"### Randomized SearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### random search cv \n# Note: this code block will take time  to execute\nfrom sklearn.model_selection import RandomizedSearchCV\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n \nparams = {\n        \"n_estimators\": [200, 400, 600   ],\n        \"criterion\" : [\"entropy\", \"gini\"],\n        \"max_depth\" : [  20, 40, 60],\n        \"max_features\" : [ .30, .50 , .70 ],    \n        \"bootstrap\" : [True, False]\n           }\n\nrs = RandomizedSearchCV(rf, params, cv=3, scoring='accuracy',verbose=10)\nrs.fit(X_train, y_train) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets do cross validation accuracy measure for rs model"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_rs = RandomForestClassifier(n_estimators= 400,max_features =0.3,\n                               max_depth =40,criterion ='entropy', bootstrap= False )\nrf_rs.fit(X_train,y_train)\naccuracy = cross_val_score(rf_rs , X, y, cv=5, scoring='accuracy')\nacc = accuracy.mean()\nacc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After RandomizedSearch, model accuracy has improved from .75 to .801\nLets create submission file for leaderboard score"},{"metadata":{},"cell_type":"markdown","source":"#### Prepare Submission file "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission_file( predictions, name):\n    submission = pd.DataFrame()\n    submission['ID'] = test['Id']     \n    submission['Cover_Type'] = predictions\n    submission.to_csv( name+'.csv',index=False, header= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testcopy = test.drop((['Id','Soil_Type7','Soil_Type15']), axis =1)\npredictions = rf_rs.predict(testcopy) \ncreate_submission_file( predictions, 'out')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}