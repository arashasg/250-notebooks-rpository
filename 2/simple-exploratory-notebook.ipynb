{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi Everyone, \nLets see  \n* How variables are distributed (EDA)\n* How the tweets are represented in 2D sentence embedding space with interactive tweet 2D Viz. \n* How to build a LGBM model using both TF-IDF Encoding and Sentence Embedding"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow_hub as hub\nfrom sklearn import metrics\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\ntarget = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')['target']\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nssub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic Exploratory Analysis"},{"metadata":{},"cell_type":"markdown","source":"Lets use nice pandas profiling which has nice boiler plate code for EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling as pp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pp.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hashtag Vizualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\n#extracting hashtags using simple regex\ntrain['hashtags']=train['text'].apply(lambda x:re.findall('#\\w*',x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nlabels=['Negative','Positive']\nno_clusters=2\nfor c in range(2):\n    print('Target:-',labels[c])\n    hts=list(train[train['target']==c]['hashtags'])\n\n    hashes=[]\n    for ht in  hts:\n        for h in ht:\n            hashes.append(h.strip())\n\n    string_hash=' '.join(hashes)\n\n    hash_values=pd.Series(hashes).value_counts()\n\n    hval=hash_values.reset_index()\n\n    #wordcloud plot\n    d = {}\n    for a, x in hval.values:\n        d[a] = x\n\n    wordcloud = WordCloud(max_font_size=40)\n    wordcloud.generate_from_frequencies(frequencies=d)\n    plt.figure(figsize=(70,70))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding tweets using Universal Sentence Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/3\")\nX_train_embeddings = embed(train.text.values)\nX_test_embeddings = embed(test.text.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interactive Tweet Embeddings Vizualization "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\n\n#2-D dimensional representation\nX_embedded = TSNE(n_components=2,perplexity=50).fit_transform(X_train_embeddings['outputs'])\nxy_df=pd.DataFrame(X_embedded)\nxy_df['tweets']=train.text.values\nxy_df['Target']=target\nxy_df.columns=['x', 'y', 'tweets','Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.models import ColumnDataSource\nfrom bokeh.models import HoverTool\nfrom bokeh.io import output_file\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\n\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = {1: 'red',0: 'blue'}\ncolors = [colormap[x] for x in xy_df['Target']]\nxy_df['colors'] = colors\n\nsrc = ColumnDataSource(xy_df)\n\n\np = figure(plot_height=650, title=\"TSNE Tweet Embedding Viz \")\np.circle(x='x', y='y',source=src,legend='Target',color='colors')\np.xgrid.grid_line_color = None\np.y_range.start = 0\np.xaxis.axis_label = \"x\"\np.yaxis.axis_label = \"y\"\np.xaxis.major_label_orientation = 1\n\nfrom bokeh.models import CustomJS\n\ncallback = CustomJS(code=\"\"\"\n    var tooltips = document.getElementsByClassName(\"bk-tooltip\");\n    for (var i = 0, len = tooltips.length; i < len; i ++) {\n        tooltips[i].style.top = \"\"; // unset what bokeh.js sets\n        tooltips[i].style.left = \"\";\n        tooltips[i].style.bottom = \"0px\";\n        tooltips[i].style.left = \"0px\";\n    }\n    \"\"\")\nhover = HoverTool(callback=callback,tooltips = [('Tweet', '@tweets'),('Target','@Target')])\n\np.add_tools(hover)\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Use your mouse cursor to see the tweets in the tooltips"},{"metadata":{},"cell_type":"markdown","source":"## TF-IDF Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#using top 50 words as the features\nvectorizer = TfidfVectorizer(max_features=30,stop_words='english')\nall_tweets=list(train['text'])+list(test['text'])\nX = vectorizer.fit_transform(all_tweets)\n\ntweet_array=X.toarray()\ntf_train=tweet_array[0:len(train)]\ntf_test=tweet_array[len(train):len(tweet_array)]\n\n## Merging TF-IDF and Universal Sentence Encoder\ntrain_df=np.concatenate([X_train_embeddings['outputs'],tf_train],axis=1)\ntest_df=np.concatenate([X_test_embeddings['outputs'],tf_test],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LGBM Model (TFIDF + Sentence Encoding)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\ntext_clf = lgb.LGBMClassifier(n_estimators=3000, learning_rate=0.05)\n\ntext_clf.fit(train_df, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=text_clf.predict(test_df)\n\nssub[\"target\"] = pred\nssub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}