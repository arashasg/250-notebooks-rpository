{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/submission.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check data"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#rename therefor the data columns\ntrain.rename(columns={'Province_State':'Province'}, inplace=True)\ntrain.rename(columns={'Country_Region':'Country'}, inplace=True)\ntrain.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#and we do the same for test set\ntest.rename(columns={'Province_State':'Province'}, inplace=True)\ntest.rename(columns={'Country_Region':'Country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# creating initial dataframe\nbridge_types = ('Date', 'Province', 'Country', 'Confirmed',\n        'Id')\ncountries = pd.DataFrame(train, columns=['Country'])\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ntrain['Countries'] = labelencoder.fit_transform(train['Country'])\n\n# #do the same for test set\ntest['Countries'] = labelencoder.fit_transform(test['Country'])\n\n#check label encoding \ntrain['Countries'].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date']= pd.to_datetime(train['Date']) \ntest['Date']= pd.to_datetime(test['Date']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.set_index(['Date'])\ntest = test.set_index(['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_time_features(train).head()\ncreate_time_features(test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping useless features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop useless columns for train and test set\ntrain.drop(['Country'], axis=1, inplace=True)\ntrain.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['Country'], axis=1, inplace=True)\ntest.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.tree import DecisionTreeRegressor  \n# reg = DecisionTreeRegressor(random_state = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n# from xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# reg= xgb.XGBRegressor(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nregressor = LogisticRegression(max_iter=5000,C=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features that will be used in the model\nx = train[['Countries','dayofweek','month','dayofyear','weekofyear']]\ny1 = train[['Confirmed']]\ny2 = train[['Fatalities']]\nx_test = test[['Countries','dayofweek','month','dayofyear','weekofyear']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\ny1=numpy.ravel(y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use model on data \nregressor.fit(x,y1)\npredict_1 = regressor.predict(x_test)\npredict_1 = pd.DataFrame(predict_1)\npredict_1.columns = [\"Confirmed_predict\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2=numpy.ravel(y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use model on data \nregressor.fit(x,y2)\npredict_2 = regressor.predict(x_test)\npredict_2 = pd.DataFrame(predict_2)\npredict_2.columns = [\"Death_prediction\"]\npredict_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot = plot_importance(regressor, height=0.9, max_num_features=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"Samle_submission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/submission.csv\")\nSamle_submission.columns\nsubmission = Samle_submission[[\"ForecastId\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission = pd.concat([predict_1,predict_2,submission],axis=1)\nFinal_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nFinal_submission = Final_submission[['ForecastId','ConfirmedCases', 'Fatalities']]\n\nFinal_submission[\"ConfirmedCases\"] = Final_submission[\"ConfirmedCases\"].astype(int)\nFinal_submission[\"Fatalities\"] = Final_submission[\"Fatalities\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.to_csv(\"submission.csv\",index=False)\nprint('Model ready for submission!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}