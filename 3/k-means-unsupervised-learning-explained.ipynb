{"cells":[{"metadata":{"id":"zfsiaKcDho8W"},"cell_type":"markdown","source":"### The data set has information about features of silhouette extracted from the images of different cars\n\nFour \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400 cars. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.\n\n","execution_count":null},{"metadata":{"id":"kVtZqLhGho8c"},"cell_type":"markdown","source":"### 1. Read the dataset using function .dropna() - to avoid dealing with NAs as of now","execution_count":null},{"metadata":{"id":"VbKTspg4ho8g","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Vehicle=pd.read_csv('../input/vehicle/vehicle.csv').dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Vehicle.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Vehicle.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_Vehicle,diag_kind='kde',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"id":"Ku4eS0ZAho8s"},"cell_type":"markdown","source":"### 2. Print/ Plot the dependent (categorical variable) - Class column","execution_count":null},{"metadata":{"id":"R1mfF_hiho8v"},"cell_type":"markdown","source":"Since the variable is categorical, you can use value_counts function","execution_count":null},{"metadata":{"id":"_dP5-zpUho81","trusted":true},"cell_type":"code","source":"df_Vehicle['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" sns.countplot(x=\"class\", data=df_Vehicle)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZFsXYI5qho9E"},"cell_type":"markdown","source":"### Check for any missing values in the data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Vehicle[df_Vehicle.isna()].count()","execution_count":null,"outputs":[]},{"metadata":{"id":"AwUdJm9qho9U"},"cell_type":"markdown","source":"### 3. Standardize the data ","execution_count":null},{"metadata":{"id":"x6z10bgjho9j"},"cell_type":"markdown","source":"Since the dimensions of the data are not really known to us, it would be wise to standardize the data using z scores before we go for any clustering methods.\nYou can use zscore function to do this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Vehicle_numeric_cols=df_Vehicle.select_dtypes(include=[np.number])\nfrom scipy.stats import zscore\ndf_scale=df_Vehicle_numeric_cols.apply(zscore)\ndf_scale","execution_count":null,"outputs":[]},{"metadata":{"id":"weIwi8cxho-C"},"cell_type":"markdown","source":"### K - Means Clustering","execution_count":null},{"metadata":{"id":"YdA5yJ1m61-L"},"cell_type":"markdown","source":"### Assign a dummy array called Cluster_error","execution_count":null},{"metadata":{"id":"PRcbAApuho-g","trusted":true},"cell_type":"code","source":"cluster_errors = []\nX=np.array(df_scale)","execution_count":null,"outputs":[]},{"metadata":{"id":"ywuVdFe2ho-t"},"cell_type":"markdown","source":"### 5. Calculate errorrs for each K","execution_count":null},{"metadata":{"id":"PJznnrkc68nf"},"cell_type":"markdown","source":"Iterating values of k from 1 to 10 fit K means model\nUsing inertia","execution_count":null},{"metadata":{"id":"uc49grvmho-2","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n# Let us check optimal number of clusters-\ncluster_range = range( 1, 10)\nfor num_clusters in cluster_range:\n  clusters = KMeans( num_clusters, n_init = 5,max_iter=100)\n  clusters.fit(X)\n  labels = clusters.labels_                     # capture the cluster lables\n  centroids = clusters.cluster_centers_         # capture the centroids\n  cluster_errors.append( clusters.inertia_ )    # capture the intertia\n# combine the cluster_range and cluster_errors into a dataframe by combining them\nclusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors} )\nclusters_df[0:10]","execution_count":null,"outputs":[]},{"metadata":{"id":"NRJo1wzqho_Q"},"cell_type":"markdown","source":"optimal value = 4","execution_count":null},{"metadata":{"id":"JIcSiPyoho_a"},"cell_type":"markdown","source":"### 6. Plotting Elbow/ Scree Plot","execution_count":null},{"metadata":{"id":"Z8Yw5XEsho_r"},"cell_type":"markdown","source":"Use Matplotlib to plot the scree plot - Note: Scree plot plots Errors vs the no of clusters","execution_count":null},{"metadata":{"id":"sJ5oE4Csho_v","trusted":true},"cell_type":"code","source":"# Elbow plot\nfrom matplotlib import pyplot as plt\nplt.figure(figsize=(12,6))\nplt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )","execution_count":null,"outputs":[]},{"metadata":{"id":"sGx_Q_4Iho_7"},"cell_type":"markdown","source":"### Find out the optimal value of K","execution_count":null},{"metadata":{"id":"i2JjEPrcho__","trusted":true},"cell_type":"code","source":"#computing of the slope using code \n#slope=error/cluster\nerrors = clusters_df['cluster_errors']\nfor i in range(8):\n    print(errors[i+1]-errors[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"5EoRD5PHhpAT"},"cell_type":"markdown","source":"### Using optimal value of K - Cluster the data. \nNote: Since the data has more than 2 dimension we cannot visualize the data. As an alternative, we can observe the centroids and note how they are distributed across different dimensions","execution_count":null},{"metadata":{"id":"68oQ0c2ThpAZ","trusted":true},"cell_type":"code","source":"# Number of clusters\nkmeans = KMeans(n_clusters=4)\n# Fitting the input data\nkmeans = kmeans.fit(X)\n# Getting the cluster labels\nlabels = kmeans.predict(X)\n# Centroid values\ncentroids = kmeans.cluster_centers_\n# Comparing with scikit-learn centroids\nprint(\"Centroid values\")\nprint(\"sklearn\")\nprint(centroids) # From sci-kit learn","execution_count":null,"outputs":[]},{"metadata":{"id":"fY5IjhFihpAm"},"cell_type":"markdown","source":"You can use kmeans.cluster_centers_ function to pull the centroid information from the instance","execution_count":null},{"metadata":{"id":"vS3GhD4UhpAx","trusted":true},"cell_type":"code","source":"colnames = df_scale.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"A2T8SxBdhpBL"},"cell_type":"markdown","source":"### 7. Store the centroids in a dataframe with column names from the original dataset given ","execution_count":null},{"metadata":{"id":"xpjTngRNhpBP","trusted":true},"cell_type":"code","source":"df_centroids=pd.DataFrame(centroids,columns=colnames)","execution_count":null,"outputs":[]},{"metadata":{"id":"SvWlZ_FzhpBY"},"cell_type":"markdown","source":"Hint: Use pd.Dataframe function ","execution_count":null},{"metadata":{"id":"EZ6nJ3BdhpBZ","trusted":true},"cell_type":"code","source":"df_centroids","execution_count":null,"outputs":[]},{"metadata":{"id":"n2kFVi2GhpBn"},"cell_type":"markdown","source":"### Use kmeans.labels_ function to print out the labels of the classes","execution_count":null},{"metadata":{"id":"Ahx91q_ghpBp","trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"id":"hm0AtttihpBv","trusted":true},"cell_type":"code","source":"prediction= kmeans.predict(X)\n#X[\"clusters\"] = prediction\nX_df = pd.DataFrame(X, columns= colnames)\nX_df[\"group\"] = prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(X_df,diag_kind='kde',hue='group')","execution_count":null,"outputs":[]},{"metadata":{"id":"SmQyHhmFhpB3"},"cell_type":"markdown","source":"## Hierarchical Clustering ","execution_count":null},{"metadata":{"id":"_zAMRDe_hpB5"},"cell_type":"markdown","source":"### 8. Variable creation","execution_count":null},{"metadata":{"id":"VESIKt49hpB6"},"cell_type":"markdown","source":"For Hierarchical clustering, we will create datasets using multivariate normal distribution to visually observe how the clusters are formed at the end","execution_count":null},{"metadata":{"id":"qpUh49bKhpB8","trusted":true},"cell_type":"code","source":"np.random.seed(101)  # for repeatability of this dataset\na = np.random.multivariate_normal([10, 0], [[3, 1], [1, 4]], size=[100,])\nb = np.random.multivariate_normal([0, 20], [[3, 1], [1, 4]], size=[50,])\nc = np.random.multivariate_normal([10, 20], [[3, 1], [1, 4]], size=[100,])","execution_count":null,"outputs":[]},{"metadata":{"id":"cu8DfP8shpCA"},"cell_type":"markdown","source":"a = np.random.multivariate_normal([10, 0], [[3, 1], [1, 4]], size=[100,])\nb = np.random.multivariate_normal([0, 20], [[3, 1], [1, 4]], size=[50,])\nc = np.random.multivariate_normal([10, 20], [[3, 1], [1, 4]], size=[100,])","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.multivariate_normal.html","execution_count":null},{"metadata":{"id":"Eui7Qgc8hpCH"},"cell_type":"markdown","source":"### 9. Combine all three arrays a,b,c into a dataframe","execution_count":null},{"metadata":{"id":"Nle34XhhhpCI","trusted":true},"cell_type":"code","source":"a=np.concatenate([a, b, c])\ndf=pd.DataFrame(a)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"lov1nQqAhpCa","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"v6JlILlihpCe"},"cell_type":"markdown","source":"### 10. Use scatter matrix to print all the 3 distributions","execution_count":null},{"metadata":{"id":"i6Nf9LznhpCg","trusted":true},"cell_type":"code","source":"sns.pairplot(df,diag_kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"id":"hILsbwkOhpCk","trusted":true},"cell_type":"code","source":"#observation:\n#1.range=4\n#max peaks for 0's = 2\n#max peaks for 1's = 2","execution_count":null,"outputs":[]},{"metadata":{"id":"Ufj36K5NhpCo"},"cell_type":"markdown","source":"### 11. Find out the linkage matrix","execution_count":null},{"metadata":{"id":"rXJAOAilhpCp"},"cell_type":"markdown","source":"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.linkage.html","execution_count":null},{"metadata":{"id":"EOxwi5gshpCt"},"cell_type":"markdown","source":"Use ward as linkage metric and distance as Eucledian","execution_count":null},{"metadata":{"id":"xJsL16lqhpCu","trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import dendrogram, linkage","execution_count":null,"outputs":[]},{"metadata":{"id":"A6YN_sjhhpC4","trusted":true},"cell_type":"code","source":"Z = linkage(df, method='ward', metric='euclidean')","execution_count":null,"outputs":[]},{"metadata":{"id":"UnVS8VYMhpC9"},"cell_type":"markdown","source":"### 12. Plot the dendrogram for the consolidated dataframe","execution_count":null},{"metadata":{"id":"oeLtemVqhpC_","trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import pdist\nplt.figure(figsize=(18, 16))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('sample index')\nplt.ylabel('Distance')\ndendrogram(Z,leaf_rotation=90.0,p=25,color_threshold=12,leaf_font_size=10,truncate_mode='level')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"QXE-T9cHhpDS"},"cell_type":"markdown","source":"### 13. Recreate the dendrogram for last 12 merged clusters ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html","execution_count":null},{"metadata":{"id":"4PKR3o5QhpDX"},"cell_type":"markdown","source":"Hint: Use truncate_mode='lastp' attribute in dendrogram function to arrive at dendrogram ","execution_count":null},{"metadata":{"id":"GDri9xtAhpDY","trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import pdist\nplt.figure(figsize=(18, 16))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('sample index')\nplt.ylabel('Distance')\ndendrogram(Z,leaf_rotation=90.0,p=12,color_threshold=12,leaf_font_size=10,truncate_mode='lastp')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"zjFjCWL5hpDr"},"cell_type":"markdown","source":"### 14. From the truncated dendrogram, find out the optimal distance between clusters which u want to use an input for clustering data","execution_count":null},{"metadata":{"id":"DQ5m6orQhpDt"},"cell_type":"markdown","source":"https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.fcluster.html","execution_count":null},{"metadata":{"id":"5-yUhkgMhpDx"},"cell_type":"markdown","source":"Optimal distance > 50 for 3 clusters","execution_count":null},{"metadata":{"id":"owSZBbSUhpEC"},"cell_type":"markdown","source":"### 15. Using this distance measure and fcluster function to cluster the data into 3 different groups","execution_count":null},{"metadata":{"id":"HLVorGUEhpEE","trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import fcluster\nz=fcluster(Z,t=50,criterion='distance')","execution_count":null,"outputs":[]},{"metadata":{"id":"Rgty9iOlhpEL","trusted":true},"cell_type":"code","source":"z","execution_count":null,"outputs":[]},{"metadata":{"id":"642Ur5TWhpEX"},"cell_type":"markdown","source":"### Use matplotlib to visually observe the clusters in 2D space ","execution_count":null},{"metadata":{"id":"YHHSylfQhpEX","trusted":true},"cell_type":"code","source":"plt.scatter(df.iloc[:,0],df.iloc[:,1],c=z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}