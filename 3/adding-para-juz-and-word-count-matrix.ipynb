{"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","version":"3.6.4","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","name":"python"}},"cells":[{"cell_type":"markdown","source":"This kernel is just some exploratory analysis on the English version of the dataset.\n\n1.   In the first version, I used the read_and_reformat function from [Sohier Dane](https://www.kaggle.com/sohier)'s kernel. Many thanks to Sohier Dane.\n\n2.   I have added the Chapter or 'Para' column using help from [Wikipedia](https://en.wikipedia.org/wiki/Juz%27).\n\n3.   I am not a huge fan of wordclouds, but I have added one just in case someone wants to explore it further.\n\n4.   A dataframe named 'counts' has been created with a matrix of all words and their respective counts, anyone willing to explore further is welcome to use it.\n\nHere it goes:","metadata":{"_uuid":"a2104b6162e76cee31b1f2229baf2c6d28104717","_cell_guid":"6aab0b76-6417-4ec2-9776-bdb0196d2f1e"}},{"cell_type":"markdown","source":"****The Dataset****\n\n***Context:***\n> The Holy Quran is the central text for 1.5 billion Muslims around the world. It literally means \"The Recitation.\" It is undoubtedly the finest work in Arabic literature and revealed by Allah (God) to His Messenger Prophet Muhammed (Peace Be Upon Him) through angel Gabriel. It was revealed verbally from December 22, 609 (AD) to 632 AD (when Prophet Muhammed (Peace Be Upon Him) died).\n\n> The book is divided into 30 parts, 114 Chapters and 6,000+ verses.\n\n***Structure:***\n\nThe dataset contains the English translation of the entire Holy Quran as a csv file, with each verse as a separate row. The Surah(Chapter) number and the Ayah(Verse) number for each row is also provided.\n\n***Goals of this Kernel:***\n\nOn first glance, we can see the data set is missing an important categorization parameter of the Quran - the Para(Part) for each verse.\n    *Goal I: We will use data from Wikipedia to add this information to the dataset.*\n\nIt is common knowledge that the earlier chapters in the Quran are quite lengthy and the later ones relatively shorter.\n    *Goal II: We will visualize the structure of chapters and verses to check if the trend holds true*\n\nThe pre-requisite for further work on this dataset is to have a list of all unique words in the entire text, along with number of times each word occurs.\n    *Goal III: We will create a matrix of each unique word and its occurence for the entirety of the text.*\n    \nWordclouds are often a goodway to have a quick glance at the most occuring words in the text.\n    *Goal IV: We will generate a wordcloud for most frequently occuring words in the Holy Quran*\n\n\nLets get started!","metadata":{}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"import pandas as pd\n\ndf = pd.read_csv('../input/en.yusufali.csv')\ndf.info()","metadata":{"_uuid":"67f34d0f0cf5b5ec089e43025f9ba28269268281","collapsed":true,"_cell_guid":"3ceb4737-fdde-4721-a4a8-b928663b4d2b"}},{"cell_type":"markdown","source":"The dataframe is missing an important column: Part or Para\n\nWe add this new columns, using the Para-Surah distribution information, courtesy of Wikipedia:","metadata":{"_uuid":"11b695bcac9eea066de2438db36f9036fe40662a","_cell_guid":"7492bb86-6f36-4c3f-b75c-efbdec20b70d"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"for col in ['Surah', 'Ayah']:\n    df[col] = pd.to_numeric(df[col])\n\ndef idx(i, j):\n    df['index'] = df.index\n    return int(df.loc[(df['Surah']==i) & (df['Ayah']==j), 'index'])\n\ncut_points = [-1, idx(2,141), idx(2,252), idx(3,92), idx(4,23), idx(4,147), idx(5,81), idx(6,110), idx(7,87), idx(8,40),\n             idx(9,92), idx(11,5), idx(12,52), idx(14,52), idx(16,128), idx(18,74), idx(20,135), idx(22,78), idx(25,20),\n             idx(27,55), idx(29,45), idx(33,30), idx(36,27), idx(39,31), idx(41,46), idx(45,37), idx(51,30), idx(57,29),\n             idx(66,12), idx(77,50), idx(114,6)]\nlabel_names = [str(i) for i in range(1, len(cut_points))]\n\nif 'Para' not in df.columns:\n    df.insert(2, 'Para', pd.cut(df.index,cut_points,labels=label_names))\ndf.drop('index', axis=1, inplace=True)\ndf['Para'] = pd.to_numeric(df['Para'])\ndf.head()","metadata":{"_uuid":"1bf04516d5b2196b135dea8aa86a0a79a74ca033","collapsed":true,"_cell_guid":"f3dbb5a1-e406-462f-8877-6a438575d420"}},{"cell_type":"markdown","source":"With the Para column added as well,\nlets have a bird's eye view of the length of Verses and how they change with Surahs:","metadata":{"_uuid":"3c1ea6b69c49fcd799735b35b86f353c54b65525","_cell_guid":"93bd2e3a-b690-48ce-a841-89aa9b8a99a5"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(1,1,1)\ndf.plot.scatter('Surah', 'Ayah', ax=ax)    ","metadata":{"_uuid":"d8414b7b0fe7eea110127fbf02518c853bc1f2c5","collapsed":true,"_cell_guid":"6a32d922-9862-41b4-9a9b-12d5f69bdb1b"}},{"cell_type":"markdown","source":"Seems like the Length of verses shortens in the later Surahs, with the first few Surahs being the longest.\n\nLet's now try to check what words appear the most along the entirety of the text.\nThis task requires us to clean the Text column from each row from punctuations, as well as not differentiate between uppercase and lowercase words.","metadata":{"_uuid":"28056543f718b234a4c81966603594d568ad694c","_cell_guid":"b66af6f1-2486-4cfb-b1d5-418463ed880a"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"all_text = []\nfor text in df['Text']:\n    all_text.append(text.split(' '))\n\npunctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"â€™\", \"?\", \"/\", \"-\", \"+\", \"&\", \"(\", \")\", \"!\"]\nclean_text = []\n\nfor item in all_text:\n    tokens = []\n    for i in item:\n        i = i.lower()\n        for p in punctuation:\n            i = i.replace(p, '')\n        tokens.append(i)\n    clean_text.append(tokens)\n\ncleaned_rows = []\n[cleaned_rows.append(' '.join(c)) for c in clean_text]\ndf['Clean Text'] = cleaned_rows\ndf.head()","metadata":{"_uuid":"eaa3889ab88e7ff99f4367aa300c1dcf4adbca9d","collapsed":true,"_cell_guid":"2daaf606-e69f-4d0b-9dec-01ece2f25f2b"}},{"cell_type":"markdown","source":"Now that each row of the text is rid of punctuations and extra spaces, let's put up a matrix of words and count their times of occurance:","metadata":{"_uuid":"b36c1029c595bcb0704851c9ef7fd1600190985d","_cell_guid":"df0991f0-690d-476f-8da9-f2da7806d8b0"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"import numpy as np\n\nunique_tokens = []\nsingle_tokens = []\n\nfor tokens in clean_text:\n    for token in tokens:\n        if token not in single_tokens:\n            single_tokens.append(token)\n        elif token not in unique_tokens:\n            unique_tokens.append(token)\n            \ncounts = pd.DataFrame(0, index=np.arange(len(clean_text)), columns=unique_tokens)\nfor index, tokens in enumerate(clean_text):\n    for token in tokens:\n        if token in unique_tokens:\n            counts.iloc[index][token] += 1\n            \ncounts.head()","metadata":{"_uuid":"bbdb63ed2b2a8db54167b5eaeb02ec026c24bfcf","collapsed":true,"_cell_guid":"20ec1a9b-d516-4f48-b4af-cdd4dde384f0"}},{"cell_type":"markdown","source":"Again, I am not a fan of wordclouds but let's put together one wordcloud for the most occuring words in the entire scripture:","metadata":{"_uuid":"44112669f337809c4672081e3397d9952775a858","_cell_guid":"a1cd4392-5d2c-4082-b143-043f539e8d1e"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"word_counts = counts.sum(axis=0)\n\nfrom wordcloud import WordCloud\n\nword_list = [word for word in word_counts.index]\nwordcloud = WordCloud(max_font_size=40).generate(' '.join(word_list))\n\nfig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(1,1,1)\nax.imshow(wordcloud, interpolation=\"bilinear\")\nax.axis(\"off\")\n","metadata":{"_uuid":"b13c543b47eeb6f0c31a7e145add53f0af8d74cf","collapsed":true,"_cell_guid":"44e179a3-7f0c-4812-9552-92e7a21fba4a"}},{"cell_type":"markdown","source":"Lets now try to put up a list of top most occuring words, excluding commonly used stopwords which includes conjunctions, prepositions etc:","metadata":{"_uuid":"f0757ee5391f5de1e6eeccf774f565189535a30f","_cell_guid":"89a2e5a3-1f66-46f3-9ecf-54d8f51e92f6"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"stopwords = ['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its', 'before', 'herself', 'had',\n             'should', 'to', 'only', 'under', 'ours', 'has', 'do', 'them', 'his', 'very', 'they', 'not', 'during',\n             'now', 'him', 'nor', 'did', 'this', 'she', 'each', 'further', 'where', 'few', 'because', 'doing',\n             'some', 'are', 'our', 'ourselves', 'out', 'what', 'for', 'while', 'does', 'above', 'between', 't',\n             'be', 'we', 'who', 'were', 'here', 'hers', 'by', 'on', 'about', 'of', 'against', 's', 'or', 'own',\n            'into', 'yourself', 'down', 'your', 'from', 'her', 'their', 'there', 'been', 'whom', 'too',\n             'themselves', 'was', 'until', 'more', 'himself', 'that', 'but', 'don', 'with', 'than', 'those',\n             'he', 'me', 'myself', 'these', 'up', 'will', 'below', 'can','theirs', 'my', 'and', 'then', 'is',\n             'am', 'it', 'an', 'as', 'itself', 'at', 'have', 'in', 'any', 'if', 'again', 'no', 'when', 'same',\n             'how', 'other', 'which', 'you', 'after', 'most', 'such', 'why', 'a', 'off', 'i', 'yours', 'so',\n             'the', 'having', 'once', 'say', 'thou', 'said', 'shall', 'thee', 'us', 'ye', 'o', 'sent', 'thy',\n             'come', 'see', 'made', 'give', 'may', ' ']\n\nclean_word_counts = []\nfor word in word_counts.index:\n    if word in stopwords:\n        word_counts.drop(word, inplace=True)\n        \nword_counts.sort_values(ascending=False).head(20)","metadata":{"_uuid":"f7d2b299eba4f2b8b6ad1e1180f7d3a352d86434","collapsed":true,"_cell_guid":"50d158d6-db2f-466b-9b7d-e0ebb3fc493f"}},{"cell_type":"markdown","source":"Let's look for the number of times some specific words occur in the text:","metadata":{"_uuid":"42ae966fca98fba6468883314828e6cf9314ba63","_cell_guid":"1d715292-4687-4f18-852a-d08b8293ad43"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"words = ['allah', 'truth', 'lie','man', 'men', 'woman', 'women', 'heaven', 'hell', 'paradise', 'hellfire', 'good', 'evil']\n\nword_times = []\nfor w in words:\n    if w not in word_times:\n        word_times.append([w, word_counts[w]])\n    \ntimes_occurence = pd.DataFrame(data = word_times, columns=['Word', 'Times'])\ntimes_occurence.head(20)","metadata":{"_uuid":"5a82b7d1c544bb4cf3781d94403aa7fd0d022342","collapsed":true,"_cell_guid":"684156f0-1480-4dac-b014-d970c2c1b93d"}},{"cell_type":"markdown","source":"This is just a very small introduction to what can be done with this dataset, you are welcome to get the most used words for each Surah or Para\n\nRegards,\nMaaz Imran","metadata":{"_uuid":"2abd43bd44bc0f5970b9d6f8878c1f655ac63182","_cell_guid":"5267f1d1-2020-4db9-b99e-32bda0121997"}}]}