{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my workbook from [Lecture 4 ipynb](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb) from FastAI course-v3.  \nI simply edited it with personal notes in order to better understand how it works, so credit goes to FastAI.  \nThis notebook is about how to implement a *Collaborative Filter*.  \nFor further info please watch the Lecture [video]( https://course.fast.ai/videos/?lesson=4).\n\nIf you are interested in other edited FastAI ipynb, you can find another one here:\n* [fastaiv1 Image Classifier](https://www.kaggle.com/gianfa/fastaiv1-image-classifier)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.collab import *\nfrom fastai.tabular import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Collaborative filtering example  \ncollab models use data in a DataFrame of user, items, and ratings."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"user,item,title = 'userId','movieId','title'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = untar_data(URLs.ML_SAMPLE)\npath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = pd.read_csv(path/'ratings.csv')\nratings.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's all we need to create and train a model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = CollabDataBunch.from_df(ratings, seed=42)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice the **x** CollabList, containing  *userId* and *movieId*, being our features; the **y** contains the *rating* values, i.e. the labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_range = [0,5.5]\nlearn = collab_learner(data, n_factors=50, y_range=y_range)\nlearn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the model resides on a [EmbeddingDotBias](https://docs.fast.ai/collab.html#EmbeddingDotBias) module, that is a simple Pytorch model (check out _source_).  \nEmbeddingDotBias wraps calls to a Pytorch [Embedding](https://pytorch.org/docs/stable/nn.html#embedding) layer, which act as a lookup table and adds a _bias_ term to the dot product result.\n\nHere the bias term lets the layer free to better generalize the representation, catching hidden influences that are not well captured by the dataset. \n\nIf you want to go a little more deeper about Embedding, [here](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html) you find the official Pytorch introduction to Word Embedding. "},{"metadata":{},"cell_type":"markdown","source":"Now the typical fit_one_cycle()"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's recap a second what we have\nOur dataset contains n rows, each one 3 dimensional, which dimensions correspond to: *userId*, *movieId*, *target*.  \nThe samples will be made by the *userId* and *movieId* values from dataset rows, and the labels will be the *target* values."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we want to predict the outcome for a specific movie, from a specific userId, we will feed the network with the userId and the movieId. That's all."},{"metadata":{},"cell_type":"markdown","source":"### Movielens 100k"},{"metadata":{"trusted":true},"cell_type":"code","source":"folder = '../input/ml-100k/'\npath = Path(folder)\nos.listdir(folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n                      names=[user,item,'rating','timestamp'])\nprint('ratings length: ', len(ratings))\nratings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1', header=None,\n                    names=[item, 'title', 'date', 'N', 'url', *[f'g{i}' for i in range(19)]])\nmovies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_movie = ratings.merge(movies[[item, title]])\nrating_movie.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = CollabDataBunch.from_df(rating_movie, seed=42, valid_pct=0.1, item_name=title)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check [collab_learner](https://docs.fast.ai/collab.html#collab_learner)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_range = [0,5.5] # range of target variable\nlearn = collab_learner(data, n_factors=40, y_range=y_range, wd=1e-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(skip_end=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.save('dotprod')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = rating_movie.groupby(title)['rating'].count()\ntop_movies = g.sort_values(ascending=False).index.values[:1000]\ntop_movies[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how we can explore the model parameters a bit."},{"metadata":{},"cell_type":"markdown","source":"### Movie bias"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_bias = learn.bias(top_movies, is_item=True)\nmovie_bias.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_ratings = rating_movie.groupby(title)['rating'].mean()\nmovie_ratings = [(b, i, mean_ratings.loc[i]) for i,b in zip(top_movies,movie_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item0 = lambda o:o[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_ratings, key=item0)[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_ratings, key=lambda o: o[0], reverse=True)[:15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Movie weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_w = learn.weight(top_movies, is_item=True)\nmovie_w.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_pca = movie_w.pca(3)\nmovie_pca.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fac0,fac1,fac2 = movie_pca.t()\nmovie_comp = [(f, i) for f,i in zip(fac0, top_movies)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0))[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_comp = [(f, i) for f,i in zip(fac1, top_movies)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0))[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxs = np.random.choice(len(top_movies), 50, replace=False)\nidxs = list(range(50))\nX = fac0[idxs]\nY = fac2[idxs]\nplt.figure(figsize=(15,15))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Further readings:\n* http://activisiongamescience.github.io/2016/01/11/Implicit-Recommender-Systems-Biased-Matrix-Factorization/\n* https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}