{"cells":[{"metadata":{},"cell_type":"markdown","source":"<style>\n@import url('https://fonts.googleapis.com/css2?family=Pangolin&display=swap');\n</style>\n\n<h1>\n    <span style = 'font-family : Pangolin, cursive;'>\n    Titanic Experimentation!\n    </span>\n</h1>\n \n\n<span style = \"color : blue\"> This is my second attempt at Titanic Dataset. This was mainly for experimenting with techniques</span>\n<hr>\n\nYou can view my First notebook [here](https://www.kaggle.com/duttasd28/titanic-0-8-accuracy-nn)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Necessary libraries and manage DataFrames\n\nWe will import necessary libraries and use pandas and numpy for our purposes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\n# Test - to be predicted\ntest = pd.read_csv('../input/titanic/test.csv')\n# Train - training data\ntrain = pd.read_csv('../input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get PassengerId from test columns. This will help in prediction later\ntestPassengerIds = test['PassengerId']\ntestPassengerIds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop some columns\ntrain.drop(['PassengerId', 'Name', 'Ticket'], inplace = True, axis = 1)\ntest.drop(['PassengerId', 'Name', 'Ticket'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imputation\n\nThere are many null values in the data. We will need to impute them that is fill them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Cabin\n\nWe will fill the`Cabin` column with our own label mapping.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us replace the values with the first letters. For example **A3** will become **A**. Also, lets assign numeric values to the data. \n\nSo, some column like 'A32' will become 'A' and then 6","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dictionary for mappinig\n# Fill each place with First letter to label mapping\n\ntrain['Cabin'].fillna(0, inplace = True)\ndef getCabin(value):\n    val_dict = {\n        'A' : 6,\n        'B' : 5,\n        'C' : 4,\n        'D' : 3,\n        'E' : 2,\n        'F' : 1,\n        'T' : 1   ## Taking T same as F, taking it to be an error     \n    }\n    return val_dict.get(str(value)[0], 0)\n\ntrain['Cabin'] = train[\"Cabin\"].apply(getCabin)\ntest['Cabin'] = test['Cabin'].apply(getCabin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Embarked\n\nEmbarked column has few missing values, so let us fill it with the most common value that is `mode`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill with most common values\ntrain['Embarked'].fillna(train['Embarked'].mode().item() , inplace = True)\n# To ensure no discrepancy\ntest['Embarked'].fillna(train['Embarked'].mode().item(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us use plotly to visualise this interactively","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.sunburst(train, path=['Embarked', 'Pclass', 'Sex'], values='Survived', title = 'Embarked -> Class -> Sex')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encode the Data\ntrain = pd.get_dummies(train, drop_first=True)\ntest = pd.get_dummies(test, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Age\nWe will impute age with the median age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute age with median\nmean = train['Age'].median()\ntrain['Age'].fillna(mean, inplace = True)\ntest['Age'].fillna(mean, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using `|` makes or operator, checks if missing in train or test\ntrain.isnull().any() | test.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that Test data has only `Fare` missing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute fare with mean of training data\nmeanFare = train['Fare'].mean()\ntest['Fare'].fillna(meanFare, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n\nNumber of features is less. So let us use Feature Engineering to add features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put the log of fare and class\ndef correctedLog(value):  # So that we do not get infinity\n    return np.log(1 + value)\n\ntrain['Status'] = train['Pclass'] + train['Fare'].apply(correctedLog)\ntest['Status'] = test['Pclass'] + test['Fare'].apply(correctedLog)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['RootAgeTimesClass'] = train['Age'].apply(np.sqrt) * train['Pclass']\ntest['RootAgeTimesClass'] = test['Age'].apply(np.sqrt) * test['Pclass']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = train['SibSp'] + train['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Young'] = train['Age'] <= train['Age'].mean()\ntest['Young'] = test[\"Age\"] <= train['Age'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['YoungMale'] = train['Young'] & train['Sex_male']\ntest['YoungMale'] = test[\"Young\"] & test['Sex_male']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:, 1: ]\ny = train.iloc[:, 0]\ny.shape, X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train['Fare']);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the Box Cox Transform\nfrom scipy.stats import boxcox\nxt,_ = boxcox(train['Fare'] + 1)\nplt.hist(xt);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2><span style = 'text-shadow: 2px 2px 5px green;'>Box Cox Transform</span></h2>\n\nBox Cox transform converts skewed values to Approximately a normal distribution. I came across and thought, lets apply!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Box Cox Transformation\ntrain['Fare'], maxlog = boxcox(train['Fare'] + 1)\ntest['Fare'] = boxcox(test['Fare'] + 1, lmbda = maxlog)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Fitting\n\nWe will use Random Forest Model for predictions. We will also use GridSearchCV to tune hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state =55, test_size = 0.2, shuffle = True)\ny_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters for Grid Search\nparamDict = {\n    'n_estimators' : [5, 10, 25, 50, 75, 100, 200, 500],\n    'max_depth' : [4, 8, 10, 15, 20, 50],\n    \n}\n# Random Forest Model\nmodel = RandomForestClassifier(n_jobs = 8)\n# Grid Search CV\nclf = GridSearchCV(estimator=model, param_grid=paramDict, n_jobs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the best parameters and score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_, clf.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(clf.predict(X_val), y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Submission\nFor training the final model, we will use all of the training data to give us additional boost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make model with best parameters, fit with all data now\nfinalModel = RandomForestClassifier(**clf.best_params_)\n\n# Fit Data\nfinalModel.fit(X, y)\n\n# Generate Predictions\ny_preds = finalModel.predict(test)\n\n#########################################################################\n# Submission File Generation\nfile_name = \"Submission_16_08_6.csv\"\n\ny_pred_series = pd.Series(y_preds.flatten(), name = 'Survived')\n\nfile = pd.concat([testPassengerIds, y_pred_series], axis = 1)\n\nfile.to_csv(file_name, index = False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Hope you like my work! If you do, please UPvote! 😃😃","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}