{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n# import lightgbm as lgb\n# import xgboost as xgb\nimport catboost as cb\nfrom catboost import Pool, cv, CatBoostClassifier\nfrom sklearn import ensemble, preprocessing, tree, model_selection, feature_selection, pipeline, metrics\nfrom sklearn.model_selection import StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spending_score_dict = {\"Low\":0,\"Average\":1,\"High\":2 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/janatahack-customer-segmentation/Train.csv')\ntest = pd.read_csv('/kaggle/input/janatahack-customer-segmentation/Test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"missings_count\"] = train.isna().sum(axis=1)\ntest[\"missings_count\"] = test.isna().sum(axis=1)\n\ntrain[\"Spending_Score\"] = train[\"Spending_Score\"].map(spending_score_dict)\ntest[\"Spending_Score\"] = test[\"Spending_Score\"].map(spending_score_dict)\n\ntrain[\"exp_div_age\"] = train[\"Work_Experience\"].div( train[\"Age\"])\ntest[\"exp_div_age\"] = test[\"Work_Experience\"].div(test[\"Age\"])\n\ntrain[\"odd_experience\"] = (train[\"Graduated\"]!=\"Yes\") & (train[\"Profession\"].isin(['Healthcare',  'Engineer', 'Doctor', 'Lawyer',\n       'Executive', 'Marketing'])).astype(int)\ntest[\"odd_experience\"] = ((test[\"Graduated\"]!=\"Yes\") & (test[\"Profession\"].isin(['Healthcare',  'Engineer', 'Doctor', 'Lawyer',\n       'Executive', 'Marketing']))).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Profession\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Var_1\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We see that all the cateogircal variables have very low cardinality/dimensionality, so there's probably no point in transforming them directly much.\n* We could stil look at feature interactions / combinations of them\n\n\n### CatBoost model\n\n\n* default params list - https://catboost.ai/docs/concepts/python-reference_parameters-list.html#python-reference_parameters-list","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = ['Gender', 'Ever_Married',  'Graduated', 'Profession','Var_1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop([\"Segmentation\"],axis=1)\nX_train[categorical_cols] = X_train[categorical_cols].fillna('\"\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install --upgrade catboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pool = Pool(\n    X_train, \n    train[\"Segmentation\"], \n    cat_features=categorical_cols,\n\n)\n\n# eval_pool = Pool(\n#     X_test, \n#     y_test, \n#     cat_features=categorical_cols,\n# )\n\ncatboost_params = {\n    'iterations': 1800,\n#     'learning_rate': 0.1,\n#     \"depth\": 2,\n#     'eval_metric': ['Logloss',\"Accuracy\"],\n     \"loss_function\":'MultiClass',\n    \n    'task_type': 'GPU',\n    'early_stopping_rounds': 15,\n#     'use_best_model': True,\n#     'verbose': 100,\n    \"silent\":True,\n#     \"verbose\": False,\n}\n\n# model = CatBoostClassifier(**catboost_params)\n\n\n# model.fit(train_pool,plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### scores = cv(train_pool,\n#             catboost_params,\n#             fold_count=4, \n#             plot=\"True\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* hyperparameter search\n* by not using a validatio nset, we risk overfitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(**catboost_params)\n\n# grid = {'learning_rate': [0.03, 0.07],\n#         'depth': [4, 6, 10],\n#         'l2_leaf_reg': [1, 3, 5, 7]}\n\n# randomized_search_result = model.randomized_search(grid,\n#                                                    train_pool,\n# #                                                    X=train_data,\n# #                                                    y=train_labels,\n#                                                    n_iter=12,\n#                                                    plot=True)\n\n\n# randomized_search_result['params'] ### {'depth': 4, 'l2_leaf_reg': 1, 'learning_rate': 0.03}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = CatBoostClassifier(**catboost_params)\n\n# grid = {'learning_rate': [0.02],\n#         'depth': [2,4, 6,8],\n#         'l2_leaf_reg': [ 1, 3],\n#        \"min_data_in_leaf\":[1,3],\n# #        \"max_leaves\":[31,61], ## cuda errors when searching this as well\n#        \"rsm\":[1,0.8]\n#        }\n\n# grid_search_result = model.grid_search(grid,\n#                                                    train_pool,\n# #                                                    n_iter=12,\n# #                                              cv=4,\n#                                                    plot=True\n#                                       )\n\n\n\n# grid_search_result['params'] \n\n# #  {'rsm': 1,\n# #  'min_data_in_leaf': 3,\n# #  'depth': 6,\n# #  'l2_leaf_reg': 3,\n# #  'learning_rate': 0.02}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So - best result after lots of grid searching is what I'd do anyway+- : default params, lower learning rate, and + min data in leaf..\n    * {'rsm': 1,\n 'min_data_in_leaf': 3,\n 'depth': 6,\n 'l2_leaf_reg': 3,\n 'learning_rate': 0.02}\n \nWe'lltrain a final model with these params and submit results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbest_params = {'iterations': 1600,\n    'learning_rate': 0.02,\n'min_data_in_leaf': 2, \n 'depth': 6,\n 'l2_leaf_reg': 3,\n#     'eval_metric': ['Logloss',\"Accuracy\"],\n     \"loss_function\":'MultiClass',\n    'task_type': 'GPU',\n    'early_stopping_rounds': 12,\n#     'use_best_model': True,\n\n    \"silent\":True,}\n\nmodel = CatBoostClassifier(**best_params)\n\nmodel.fit(train_pool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[categorical_cols] = test[categorical_cols].fillna('\"\"')\npreds = model.predict(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Segmentation\"] = preds\n\ndisplay(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[[\"ID\",\"Segmentation\"]].to_csv(\"output_preds_catboost_v3.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* more indepth hyperparam search - e.g. \n    * https://www.kaggle.com/shivampanwar/catboost-and-hyperparameter-tuning-using-bayes\n    * https://github.com/lmassaron/kaggledays-2019-gbdt/blob/master/Kaggle%20Days%20Paris%20-%20Skopt%20%2B%20CatBoost%20solution.ipynb\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}