{"cells":[{"metadata":{"_uuid":"1bdc4fc7dc115276b96e794172bd61b04c66a6ee"},"cell_type":"markdown","source":"### An exploratory analysis of this dataset\nMy conclusion: There's too little documentation on the column contents to make any sensible use of this dataset\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt; plt.rcdefaults()\nimport sklearn\nimport csv\n%matplotlib inline \nplt.rcParams[\"figure.figsize\"] = [16, 12]\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nfilename = check_output([\"ls\", \"../input\"]).decode(\"utf8\").strip()\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"filename","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cd38097282780ba275ba330297859dc822ab852"},"cell_type":"code","source":"def read_csv(filename):\n    lines = []\n    with open(filename, 'r') as t:\n        spamreader = csv.reader(t, delimiter=',', quotechar='\"')\n        for row in spamreader:\n            lines.append(row)\n    t.close()\n    return lines\n\nall_reviews = read_csv('../input/br.csv')\n\nprint(all_reviews[0:3])\nprint(f\"Number of reviews: {len(all_reviews)}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8738f132307448e28af7e2af5cbfb61cf5598697"},"cell_type":"markdown","source":"Now lets separate the reviews by their ratings. I chose to classify all reviews with a rating below 2.0 as a negative review, those with a rating higher than 2.0 and lower than 4.0 as a neutral one, and the rest as positive ones. I chose high thresholds for the 'neutral' and 'positive' labels, because the distribution of review ratings is skewed to higher numbers. "},{"metadata":{"trusted":true,"_uuid":"5f331098c906beb2a0684be6321bf986f55173c3"},"cell_type":"code","source":"negative_reviews = [row for row in all_reviews[1:] if float(row[3]) < 2.5]\nneutral_reviews = [row for row in all_reviews[1:] if float(row[3]) >= 2.5 and float(row[3]) < 4.0]\npositive_reviews = [row for row in all_reviews[1:] if float(row[3]) >= 4.0]\n\nprint(f\"Negative reviews: {len(negative_reviews)}\")\nprint(f\"Neutral reviews: {len(neutral_reviews)}\")\nprint(f\"Positive reviews: {len(positive_reviews)}\")\n\nobjects = ('Negative', 'Neutral', 'Positive')\ny_pos = np.arange(len(objects))\nperformance = [len(negative_reviews),len(neutral_reviews),len(positive_reviews)]\n \nplt.bar(y_pos, performance, align='center', alpha=0.25)\nplt.xticks(y_pos, objects)\nplt.ylabel('Number of reviews')\nplt.title('Rating quality')\n \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b338c77033938bf51642b56276f33eb04a75816c"},"cell_type":"markdown","source":"Now let's see what the average reviewscores are per book, creating a dictionary that uses the bookID as its key and stores the reviewscore and reviewtext."},{"metadata":{"trusted":true,"_uuid":"61f29a4d3cbbd058ea6b33ea70ba8d66377dca7c"},"cell_type":"code","source":"bookid_review_tuples = [(row[0], float(row[3]), row[8]) for row in all_reviews[1:]]\nreview_per_book = {}\nfor bookid,rating,review in bookid_review_tuples:\n    try:\n        new_entry = review_per_book[bookid]\n        new_entry.append((rating,review))\n        review_per_book[bookid] = new_entry\n    except:\n        review_per_book[bookid] = [(rating,review)]\nprint(f\"Number of books found in dictionary: {len(review_per_book)}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15797679791b8555f153e100e14c2f145e157fa2"},"cell_type":"markdown","source":"Apparently, each book ID only appears once. This tells us that the ratings do not correspond with the review on index 8, but with the average of all {ratingsCount} reviews given for the book. This dataset barely has any documentation, so we have to make some assumptions. The review and reviewer provided on indices 6,7 and 8 might've been the topreview, or a randomly picked one; We don't know. Having only one review per book and no corresponding rating, makes ** this dataset useless for classification (e.g. whether reviews are positive or not).** We can still use this dataset to see which books have the highest ratings and which have the lowest. Let's select only those books that have received a high number of ratings (more than 1000). After that, you can ofcourse also do some Natural Language Processing on the reviews, to see what "},{"metadata":{"trusted":true,"_uuid":"90cdb5f10a29ce4ac7cbe69685e0398c9f68ba98"},"cell_type":"code","source":"MIN_REVIEW_THRESHOLD = 1000\nflop_books = [review for review in negative_reviews if int(review[4]) > MIN_REVIEW_THRESHOLD]\ntop_books = [review for review in positive_reviews if float(review[3]) > 4.6 and int(review[4]) > MIN_REVIEW_THRESHOLD]\nprint(f\"Number of flop books found in dictionary: {len(flop_books)}\")\nprint(f\"Number of top books found in dictionary: {len(top_books)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6f7d188a4d2d08513a491debf20c2efababecf6","scrolled":false},"cell_type":"code","source":"for book in top_books[-10:]:\n    print(f\"BookID: {book[0]} - Title: {book[1]}. Written By: {book[2]}. Rating: {float(book[3])}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b794c9be44eb1014e09ff28e0db11712cc836bf"},"cell_type":"markdown","source":"Apparently, BookIDs are different even if they refer to the same book. Let's see what happens when we compare the reviews for these three bookids using our previously created dictionary. Will they be different?"},{"metadata":{"trusted":true,"_uuid":"5479a9fa4758085061dd89c2cfa65fcf00aec506"},"cell_type":"code","source":"print(review_per_book['330586'])\nprint(review_per_book['330587'])\nprint(review_per_book['330588'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d88a5ff407d9f8fc84d54648a8cb8a2f7b5b3d0a"},"cell_type":"markdown","source":"Apparently, the column \"bookID\" contains neither a book ID (there are multiple book IDs that refer to the same book), nor a review ID (different review IDs would then refer to the same review). Anyone has any interesting ideas on how to use this data?"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}